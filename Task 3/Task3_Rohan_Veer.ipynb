{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# JP Morgan Chase Forage Virtual Experience\n",
        "# Task 3: Loan Default Prediction & Expected Loss Estimation\n",
        "# Author: Rohan Veer\n",
        "# Date: October 2025\n",
        "#\n",
        "# Note: A detailed presentation of results and insights\n",
        "# is available separately (PDF file titled:\n",
        "# \"Loan_Default_Prediction_Presentation.pdf\").\n",
        "# View the full project presentation here:\n",
        "# https://drive.google.com/file/d/1digY6FcX3dgUah_Oy8PT_phEXW4UIsbk/view?usp=sharing\n"
      ],
      "metadata": {
        "id": "BAV9X6_EQJsG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "igjVgZ5JQcfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EYFnG7aO8rP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import joblib\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 42\n",
        "CSV_PATH = \"Task 3 and 4_Loan_Data.csv\"  # update if your file is elsewhere\n",
        "LOGISTIC_MODEL_PATH = \"logistic_model.joblib\"\n",
        "SCALER_PATH = \"scaler.joblib\"\n",
        "RF_MODEL_PATH = \"rf_model.joblib\""
      ],
      "metadata": {
        "id": "mT84iiObPC8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path=CSV_PATH):\n",
        "    \"\"\"Load dataset from CSV.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"CSV file not found at {path}. Put the CSV in same folder or update CSV_PATH.\")\n",
        "    df = pd.read_csv(path)\n",
        "    return df"
      ],
      "metadata": {
        "id": "evVQIGIyPErZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df):\n",
        "    \"\"\"Drop ID, separate X and y, return train/test splits and scaler-fitted arrays for LR.\"\"\"\n",
        "    X = df.drop(columns=[\"customer_id\", \"default\"])\n",
        "    y = df[\"default\"]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    return X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler"
      ],
      "metadata": {
        "id": "hSuEmnz-PGme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_models(X_train, X_train_scaled, y_train):\n",
        "    \"\"\"Train Logistic Regression (on scaled features) and Random Forest (on raw features).\"\"\"\n",
        "    log_model = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
        "    log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    rf_model = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    return log_model, rf_model\n"
      ],
      "metadata": {
        "id": "MHIgUL-rPHua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, X_test_scaled, y_test, model_type=\"logistic\"):\n",
        "    \"\"\"Return accuracy and ROC-AUC. model_type decides which X to use.\"\"\"\n",
        "    if model_type == \"logistic\":\n",
        "        preds = model.predict(X_test_scaled)\n",
        "        proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "    else:\n",
        "        preds = model.predict(X_test)\n",
        "        proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    auc = roc_auc_score(y_test, proba)\n",
        "    return acc, auc"
      ],
      "metadata": {
        "id": "D0Pf1H1zPMgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_expected_loss(model, scaler, borrower_info, recovery_rate=0.1):\n",
        "    \"\"\"\n",
        "    Predict PD and Expected Loss for a single borrower.\n",
        "    borrower_info: dict with keys:\n",
        "      credit_lines_outstanding, loan_amt_outstanding, total_debt_outstanding,\n",
        "      income, years_employed, fico_score\n",
        "    returns: (pd_value, expected_loss)\n",
        "    \"\"\"\n",
        "    cols = [\"credit_lines_outstanding\", \"loan_amt_outstanding\", \"total_debt_outstanding\",\n",
        "            \"income\", \"years_employed\", \"fico_score\"]\n",
        "    borrower_df = pd.DataFrame([borrower_info], columns=cols)\n",
        "\n",
        "    borrower_scaled = scaler.transform(borrower_df)\n",
        "    pd_value = model.predict_proba(borrower_scaled)[:, 1][0]\n",
        "    expected_loss = pd_value * (1 - recovery_rate) * borrower_info[\"loan_amt_outstanding\"]\n",
        "    return pd_value, expected_loss"
      ],
      "metadata": {
        "id": "Dugxo43zPPXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    # 1. Load data\n",
        "    df = load_data(CSV_PATH)\n",
        "    print(\"Loaded data shape:\", df.shape)\n",
        "\n",
        "    # 2. Prepare data\n",
        "    X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler = prepare_data(df)\n",
        "    print(\"Train/test split sizes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "    # 3. Train\n",
        "    log_model, rf_model = train_models(X_train, X_train_scaled, y_train)\n",
        "\n",
        "    # 4. Evaluate\n",
        "    log_acc, log_auc = evaluate_model(log_model, X_test, X_test_scaled, y_test, model_type=\"logistic\")\n",
        "    rf_acc, rf_auc = evaluate_model(rf_model, X_test, X_test_scaled, y_test, model_type=\"rf\")\n",
        "\n",
        "    print(\"\\nMODEL PERFORMANCE\")\n",
        "    print(f\"Logistic Regression - Accuracy: {log_acc:.4f}, ROC-AUC: {log_auc:.6f}\")\n",
        "    print(f\"Random Forest       - Accuracy: {rf_acc:.4f}, ROC-AUC: {rf_auc:.6f}\")\n",
        "\n",
        "    # 5. Save Logistic model and scaler (for reproducibility / deployment)\n",
        "    joblib.dump(log_model, LOGISTIC_MODEL_PATH)\n",
        "    joblib.dump(scaler, SCALER_PATH)\n",
        "    joblib.dump(rf_model, RF_MODEL_PATH)\n",
        "    print(f\"\\nSaved logistic model to {LOGISTIC_MODEL_PATH} and scaler to {SCALER_PATH}\")\n",
        "\n",
        "    # 6. Example prediction\n",
        "    sample_borrower = {\n",
        "        \"credit_lines_outstanding\": 4,\n",
        "        \"loan_amt_outstanding\": 20000.0,\n",
        "        \"total_debt_outstanding\": 15000.0,\n",
        "        \"income\": 60000.0,\n",
        "        \"years_employed\": 5,\n",
        "        \"fico_score\": 620\n",
        "    }\n",
        "    pd_value, expected_loss = predict_expected_loss(log_model, scaler, sample_borrower, recovery_rate=0.1)\n",
        "    print(\"\\nSAMPLE BORROWER PREDICTION\")\n",
        "    print(f\"Predicted PD: {pd_value:.6f}\")\n",
        "    print(f\"Expected Loss (recovery 10%): {expected_loss:.2f}\")\n",
        "\n",
        "    # 7. Optionally create a small results CSV for quick reference\n",
        "    example_out = pd.DataFrame([{\n",
        "        \"pd\": pd_value,\n",
        "        \"expected_loss\": expected_loss,\n",
        "        **sample_borrower\n",
        "    }])\n",
        "    example_out.to_csv(\"example_prediction.csv\", index=False)\n",
        "    print(\"Saved example_prediction.csv with sample prediction.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q0Hu6Z9PUnL",
        "outputId": "dde15fa0-01f7-4317-ea7f-2bc86315a84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data shape: (10000, 8)\n",
            "Train/test split sizes: (8000, 6) (2000, 6)\n",
            "\n",
            "MODEL PERFORMANCE\n",
            "Logistic Regression - Accuracy: 0.9990, ROC-AUC: 0.999988\n",
            "Random Forest       - Accuracy: 0.9960, ROC-AUC: 0.999893\n",
            "\n",
            "Saved logistic model to logistic_model.joblib and scaler to scaler.joblib\n",
            "\n",
            "SAMPLE BORROWER PREDICTION\n",
            "Predicted PD: 0.994597\n",
            "Expected Loss (recovery 10%): 17902.74\n",
            "Saved example_prediction.csv with sample prediction.\n"
          ]
        }
      ]
    }
  ]
}